{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Memoria**\n",
    "Breve descripción de los pasos realizados en el Proyecto de ML\n",
    "\n",
    "# **1°) Feature Engineering**\n",
    "* Carga del dataset extraído de Kaggle\n",
    "* Nos centraremos en los datos de EE.UU \n",
    "1. Outliers: se trato de quedarnos con los datos en la cual la target<1.5 IQR (rango intercuartilico), pero reducia notablemente el dataset\n",
    "2. Datos Faltantes: se tuvieron en cuenta y se los imputo como valores 'Unknown', considerando que hacia referencia a datos que el usuario no deseaba proporcionar.\n",
    "3. **Transformación Variables Categóricas**: \n",
    "    + Se realizaron Agrupaciones a las variables categóricas que contaban con un gran numero de clases\n",
    "    + Aplicamos el **Método OHE** (dummies).\n",
    "* Matriz de Correlación \n",
    "4. **Transformaciones y escalado Variables Numéricas**:\n",
    "    + Se aplicaron los 4 siguientes Escalados:\n",
    "    + **Min-Max**: entre el min y max, tenemos entre -1 y 1 \n",
    "    + **Max Abs**: se coge el max abs \n",
    "    + **Estandarización**: quitamos la media de cada obs y tenemos 1 de varianza\n",
    "    + **Normalización**: la curva normal, normalizar los valores\n",
    "\n",
    "# **2°) Baseline Modelling**\n",
    "* 1°) Modelos Originales: se testearon los modelos con las variables originales.\n",
    "    + Metricas: nos basamos principalmente en el R2 y el MAE.\n",
    "    + Conclusiones:\n",
    "        + > En esta fase se descarta el SVR, observando el bajo R2 lo que indica un grado de prediccion casi nulo, sumado a que este tipo de modelo además cuenta con un gran coste computacional. \n",
    "\n",
    "        + > **LinearRegressor** y **XGBRegressor** parecen ser los más óptimos.\n",
    "\n",
    "        + > A priori si observamos las métricas, el grado de predicción no parece ser alentador. Una de las posibles causas puede ser la falta de datos, es decir, se necesitaria un mayor volumen de registros. Y otro factor, es la falta de datos por titles, es decir, los datos no estan balanceados segun los titles lo que afecta notablemente a la hora de realizar predicciones sobre un determinado trabajo. Tambien el rango de los salarios influye debido a lo que se menciono anteriormente.\n",
    "* 2°) Modelos Originales con Escalados: En esta segunda etapa probamos con los distintos escalados todos los Modelos para ver si se logra alguna mejoria en alguno.\n",
    "    + Metricas\n",
    "    + Conclusiones\n",
    "        + > Luego de realizar los 4 Escalados no hubo una diferencia significativa en cuanto a las métricas, por lo que se opta por dejar el Estandarizado y proseguir con las siguientes etapas para tratar de mejorar los modelos.\n",
    "\n",
    "* 3°) Modelos con las Features mas Importantes: En esta tercer etapa, a traves del Random Forest obtuvimos las features importance, es decir, las columnas que mas relevancia/peso tienen a la hora de realizar predicciones.\n",
    "    + Metricas\n",
    "    + Conclusiones**\n",
    "        + > Debido a que no se notó una mejoría en las Métricas al realizar una Reducción de Dimensión (se eliminaron las 4 features con menor correlacion), se decide utilizar todas las features originales.\n",
    "\n",
    "        + > Nos quedaremos con los Modelos: \n",
    "            + * **1° XGBRegressor**\n",
    "            + * **2° RandomForest**\n",
    "\n",
    "* 4°) Modelos con Optimización de los Hiperparámetros: En esta 4 etapa tomamos el XGBRegressor  y RandomForest y les aplicaremos el **GridSearchCV** cuya funcion es mejorarlos a través de la optimizacion de los parámetros. A su vez, se realizó una Validacion Cruzada la cual usamos un k=3 para reducir los tiempos y sobretodo para no tener Overfitting.\n",
    "\n",
    "    + Conclusiones\n",
    "        + > Utilizando el GridSearchCV para optimizar los hiperparámetros se obtuvo una mejoria en el R2 de aprox 1,5%.\n",
    "\n",
    "        + > Tambien se logró reducir el MAE.\n",
    "\n",
    "        + > Decidimos llevar a Produccion este modelo ya que es el con el que mejores Metricas obtuvimos a pesar de que no sean las óptimas a la hora de obtener buenas predicciones.\n",
    "\n",
    "# **3°) Guardado de Modelo**\n",
    "Guardamos el Modelo en pickle para poner en Produccion en la Webb App\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
